<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Next steps &mdash; TopasOpt  documentation</title>
      <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script src="_static/jquery.js?v=5d32c60e"></script>
        <script src="_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
        <script src="_static/documentation_options.js?v=5929fcd5"></script>
        <script src="_static/doctools.js?v=888ff710"></script>
        <script src="_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="_static/js/theme.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Environment set up" href="EnvironmentSetup.html" />
    <link rel="prev" title="Development example" href="DevelopmentExample.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="index.html" class="icon icon-home">
            TopasOpt
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="worked_examples.html">Worked Examples</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Next steps</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#designing-objective-functions">Designing objective functions</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#competing-objectives">Competing objectives</a></li>
<li class="toctree-l3"><a class="reference internal" href="#hard-boundaries">Hard boundaries</a></li>
<li class="toctree-l3"><a class="reference internal" href="#log-of-objective-function">Log of objective function</a></li>
<li class="toctree-l3"><a class="reference internal" href="#handling-constraints">Handling constraints</a></li>
<li class="toctree-l3"><a class="reference internal" href="#assess-noise-in-the-objective-function">Assess noise in the objective function</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#convergence-criteria">Convergence criteria</a></li>
<li class="toctree-l2"><a class="reference internal" href="#all-optimisers">All Optimisers</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#improving-accuracy">Improving accuracy</a></li>
<li class="toctree-l3"><a class="reference internal" href="#read-in-and-plot-a-previous-log-file">read in and plot a previous log file</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#bayesianoptimiser">BayesianOptimiser</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#restart-an-optimisation">Restart an optimisation</a></li>
<li class="toctree-l3"><a class="reference internal" href="#load-and-interact-with-the-gaussian-process-model">Load and interact with the gaussian process model</a></li>
<li class="toctree-l3"><a class="reference internal" href="#setting-length-scales-in-the-gaussian-process-model">Setting length scales in the gaussian process model</a></li>
<li class="toctree-l3"><a class="reference internal" href="#tuning-exploration-exploitation">Tuning exploration/ exploitation</a></li>
<li class="toctree-l3"><a class="reference internal" href="#handling-noisy-objective-functions">Handling noisy objective functions</a></li>
<li class="toctree-l3"><a class="reference internal" href="#for-the-hard-core-nerds">For the hard core nerds…</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#neldermeadoptimiser">NelderMeadOptimiser</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#choose-the-starting-simplex">Choose the starting simplex</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="EnvironmentSetup.html">Environment set up</a></li>
<li class="toctree-l1"><a class="reference internal" href="DeveloperNotes.html">Developer Notes</a></li>
<li class="toctree-l1"><a class="reference internal" href="code_docs.html">Code documentation</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">TopasOpt</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="index.html" class="icon icon-home" aria-label="Home"></a></li>
      <li class="breadcrumb-item active">Next steps</li>
      <li class="wy-breadcrumbs-aside">
            <a href="_sources/next_steps.md.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="next-steps">
<h1>Next steps<a class="headerlink" href="#next-steps" title="Link to this heading"></a></h1>
<p>These instructions assume you have already worked through at least one of the worked examples.
If you have not, it is strongly recommended that you go back and do so before proceeding.</p>
<section id="designing-objective-functions">
<h2>Designing objective functions<a class="headerlink" href="#designing-objective-functions" title="Link to this heading"></a></h2>
<p>The optimisers implemented in this library are so called ‘black box’ optimisers, which means they don’t know anything about the objective function or make any assumptions about it’s shape. This means that you can literally make your objective function anything you want, the only requirement is that it returns a number to the optimiser.</p>
<p>Having said this, having a well crafted objective function can absolutely be the difference between success and failure. The below are some things you may want to consider when you are writing your objective function.</p>
<section id="competing-objectives">
<h3>Competing objectives<a class="headerlink" href="#competing-objectives" title="Link to this heading"></a></h3>
<p>Let’s take a trivial example: say you are building a table; you want to minimise the mass, but maximise the strength. Clearly these objectives will ‘fight’ each other.</p>
<p>In this library, we do ‘single criteria optimisation’, which means the objective function can only return one number. That means you have to encapsulate both priorities in the objective function. A simple way to do this is below:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">objective_function</span> <span class="o">=</span> <span class="o">-</span><span class="n">weight_strength</span><span class="o">*</span><span class="n">strength</span> <span class="o">+</span> <span class="n">weight_mass</span><span class="o">*</span><span class="n">mass</span>
</pre></div>
</div>
<p>(Note that we want strength to be high - since we are <strong>minimising</strong> this function, we use -strength).</p>
<p>Clearly, the ‘best’ solution that will be found in this case depends on how you weight these objectives. This can take some trial and error and experience to get right.</p>
<p>A more elegant, but more complicated way to handle these situations is via <a class="reference external" href="https://en.wikipedia.org/wiki/Multi-objective_optimization">multi-objective or pareto optimisation</a>. We do not currently have an implementation of this for this library although pull requests are welcome!</p>
</section>
<section id="hard-boundaries">
<h3>Hard boundaries<a class="headerlink" href="#hard-boundaries" title="Link to this heading"></a></h3>
<p>Let’s continue using our table from above. Although we have initially stated that we want maximum strength, this is probably not really true - we just want the strength to be above some threshold. This is another very common situation, and in code looks like below :</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">if</span> <span class="n">strength_sufficient</span><span class="p">:</span>
	<span class="n">objective_function</span> <span class="o">=</span> <span class="mi">0</span> 
<span class="k">else</span><span class="p">:</span>
	<span class="n">objective_function</span> <span class="o">=</span> <span class="n">large_number</span>  <span class="c1"># penalise the case where our condition is not met</span>
</pre></div>
</div>
<p>The problem with this form is that it results in a discontinuity in the objective function. Although the optimisation will still run, it may not bconverge as fast as it could. In such cases it is better to “smooth” the discontinuity using a <a class="reference external" href="https://en.wikipedia.org/wiki/Sigmoid_function">sigmoid function</a>. Having said this, in my experience with the Bayesian optimiser it didn’t actually make much difference - but at the very least a smooth objective function gives reviewers less to complain about ;-)</p>
</section>
<section id="log-of-objective-function">
<h3>Log of objective function<a class="headerlink" href="#log-of-objective-function" title="Link to this heading"></a></h3>
<p>It is pretty common that large swarthes of the objective space are ‘bad’ i.e. have a high objective function. In some cases, it is desirable to flatten out these bad regions so the optimisation algorithm doesn’t get ‘distracted’ by high gradient errors in ‘bad regions’. For instance, maybe your objective function ranges between 0 and 100, but you are really interested in the spaces between 0 and 1. The optimiser may find a very steep gradient that goes from 20 to 2, which to it may seem more interesting than a shallow gradient in a different region that may go from 2 to 1.2.</p>
<p>In such situations, you may wish to take the log of the objective function. This has the effect of surpressing the differences in high value  (bad)regions and enhancing the differences in the low value (good) regions. Note however that this will also emphasise low level noise in your objective function!</p>
</section>
<section id="handling-constraints">
<h3>Handling constraints<a class="headerlink" href="#handling-constraints" title="Link to this heading"></a></h3>
<p>At the moment, this code handles boundaries (0&lt;=x&lt;=1) but not constraints (x&lt;=2*y). Nevertheless, it is very common that the allowed values for one variable are dependant on the values of another variable.</p>
<p>I hope that in the future we will be able to handle these cases in the problem set up, but for now, I recomend just returning a high number. Although this does contradict my earlier advice to try and ensure the objective function is smooth, it is less important to ensure this in ‘bad’ regions, since a good algorithm will not pay too much attention to these regions anyway.</p>
</section>
<section id="assess-noise-in-the-objective-function">
<h3>Assess noise in the objective function<a class="headerlink" href="#assess-noise-in-the-objective-function" title="Link to this heading"></a></h3>
<p>You can use your GenerateTopasScripts function to create 10 identical scripts, run them all, and then assess the reslts with TopasObjectiveFunction. If the noise in the objective function is higher than the precision you would ultimately like to converge to then you are unlikely to get a great result. E.g. if the noise in the objective function is 20% and you hope to be within 10% of the true optimum you are in trouble. For the Bayesian optimiser, you may be able to handle noise by increasing bayes_GP_alpha.</p>
</section>
</section>
<section id="convergence-criteria">
<h2>Convergence criteria<a class="headerlink" href="#convergence-criteria" title="Link to this heading"></a></h2>
<p>At the moment, this code is primarily set up to terminate based on number of iterations, e.g. if you figure you have 24 hours of computing time available, figure out how many iterations you can run for. It is of course possible in principle to use different convergence criteria - e.g.</p>
<ul class="simple">
<li><p>if the solution hasn’t been improved on for N iterations, stop</p></li>
<li><p>if the solution is x times better than the starting solution, stop</p></li>
</ul>
<p>At the moment, these aren’t coded , but will be considered in future versions!</p>
</section>
<section id="all-optimisers">
<h2>All Optimisers<a class="headerlink" href="#all-optimisers" title="Link to this heading"></a></h2>
<section id="improving-accuracy">
<h3>Improving accuracy<a class="headerlink" href="#improving-accuracy" title="Link to this heading"></a></h3>
<p>If you think you require better accuracy than the first result you get, you have a few options:</p>
<ul class="simple">
<li><p>Run more iterations.</p></li>
<li><p>Use these parameters as a starting guess, and run a new optimisation with a reduced search space</p></li>
<li><p>Note that there <strong>will</strong> be noise in the objective function. This is an inherent aspect of the monte carlo method, especially when we are trying to run fast simulations. At some point, this noise will limit the accuracy the optimiser could even theoretically achieve. See assessing and handling noise in the objective function below.</p></li>
</ul>
</section>
<section id="read-in-and-plot-a-previous-log-file">
<h3>read in and plot a previous log file<a class="headerlink" href="#read-in-and-plot-a-previous-log-file" title="Link to this heading"></a></h3>
<p>Whenever an optimisation is run, a log file is created at BaseDirectory / SimulationName / logs/ OptimisationLogs.txt.
You can read this file into a dictionary as follows:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">TopasOpt.utilities</span> <span class="kn">import</span> <span class="n">ReadInLogFile</span>

<span class="n">LogFileLoc</span> <span class="o">=</span> <span class="s1">&#39;/home/brendan/Documents/temp/NMtest/logs/OptimisationLogs.txt&#39;</span>
<span class="n">LogFileDict</span> <span class="o">=</span> <span class="n">ReadInLogFile</span><span class="p">(</span><span class="n">LogFileLoc</span><span class="p">)</span>
</pre></div>
</div>
<p>You are then free to create your own plotting routines to present this data any way
you want, but we do provide a default ploting function:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">TopasOpt.utilities</span> <span class="kn">import</span> <span class="n">PlotLogFile</span>

<span class="n">LogFileLoc</span> <span class="o">=</span> <span class="s1">&#39;/home/brendan/Documents/temp/NMtest/logs/OptimisationLogs.txt&#39;</span>
<span class="n">PlotLogFile</span><span class="p">(</span><span class="n">LogFileLoc</span><span class="p">)</span>
</pre></div>
</div>
</section>
</section>
<section id="bayesianoptimiser">
<h2>BayesianOptimiser<a class="headerlink" href="#bayesianoptimiser" title="Link to this heading"></a></h2>
<p>The following is a list of things that you can also do with this optimiser (</p>
<section id="restart-an-optimisation">
<h3>Restart an optimisation<a class="headerlink" href="#restart-an-optimisation" title="Link to this heading"></a></h3>
<p>Sometimes an optimisation is terminated prematurely because of time limits on job submissions or because your partner turned your computer off.</p>
<p>In such situations, it is easy to restart the optimisation; you just have to change Optimiser.RunOptimisation() to Optimiser.RestartOptimisation().</p>
<p>This can also be used in situations where you initially thought that 20 iterations would be sufficient but later want to extend this to 40 iterations for instance.</p>
</section>
<section id="load-and-interact-with-the-gaussian-process-model">
<h3>Load and interact with the gaussian process model<a class="headerlink" href="#load-and-interact-with-the-gaussian-process-model" title="Link to this heading"></a></h3>
<p>One of the nice things about bayesian optimisation is that at the end of it, there is a model which can be used to predict what the objective function might look like at some particular point. Of course whether or not this is useful depends on how well the model was trained, but assuming you have trained a useful model, you can use the logs from a previous run to read in and interact with the gaussian process model. The below script demonstrates this:</p>
</section>
<section id="setting-length-scales-in-the-gaussian-process-model">
<h3>Setting length scales in the gaussian process model<a class="headerlink" href="#setting-length-scales-in-the-gaussian-process-model" title="Link to this heading"></a></h3>
<p>Length scales are used in the kernel of the gaussian process model. In simple language, the length scales indicate how close together two points should be to expect them to have a fairly similar value. The length scales are integral in getting a good fit of the gaussian process model to</p>
<p>In this code, the default behaviour is to set the length scales to 10% of the allowed range for each parameter. E.g. if you have a parameter with a lower limit of 1 and an upper limit of 3, the default length scale would be (3-1)*0.1 = 0.2.</p>
<p>This approach works pretty well as the default. However, there may be situations when you wish to apply a little more finesse. In that case, you can also pass an array for length_scales, with one value per parameter, e.g.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">Optimiser</span> <span class="o">=</span> <span class="n">to</span><span class="o">.</span><span class="n">BayesianOptimiser</span><span class="p">(</span><span class="n">optimisation_params</span><span class="p">,</span> <span class="n">BaseDirectory</span><span class="p">,</span> <span class="n">SimulationName</span><span class="p">,</span> <span class="n">OptimisationDirectory</span><span class="p">,</span> <span class="n">TopasLocation</span><span class="o">=</span><span class="s1">&#39;~/topas37&#39;</span><span class="p">,</span> <span class="n">ReadMeText</span><span class="o">=</span><span class="n">ReadMeText</span><span class="p">,</span> <span class="n">Overwrite</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span><span class="n">length_scales</span><span class="o">=</span><span class="p">[</span><span class="n">par1_scale</span><span class="p">,</span> <span class="n">par2_scale</span><span class="p">,</span> <span class="n">par3_scale</span><span class="p">,</span> <span class="n">etc</span><span class="o">.</span><span class="p">])</span>
</pre></div>
</div>
<p>Note that no matter what you pass in as the initial length scales, they will be optimised behind the scenes. If you look at the log file of a completed run, it will tell you at the end what the initial
length scales used were, and what the fitted length scales at the end of the run (e.g. the data driven answer) were. If you plan to run the optimiser again, you will likely get faster convergence if you use the fitted length scales to start off with.</p>
</section>
<section id="tuning-exploration-exploitation">
<h3>Tuning exploration/ exploitation<a class="headerlink" href="#tuning-exploration-exploitation" title="Link to this heading"></a></h3>
<p>You can read more about this concept <a class="reference external" href="https://github.com/fmfn/BayesianOptimization/blob/master/examples/exploitation_vs_exploration.ipynb">here</a>. The exploration/exploitation tradeoff is controlled by the parameter <code class="docutils literal notranslate"><span class="pre">bayes_UCBkappa</span></code> by default it is set to 5, which is a fairly exploratory approach. You can make it higher for more exploration, or lower for more exploitation. By default, we also have a <code class="docutils literal notranslate"><span class="pre">bayes_KappaDecayIterations=10</span></code>. this means that over the last 10 iterations, the algorithm will begin to come more and more exploitive. So basically the default settings give you the best of both worlds!!</p>
</section>
<section id="handling-noisy-objective-functions">
<h3>Handling noisy objective functions<a class="headerlink" href="#handling-noisy-objective-functions" title="Link to this heading"></a></h3>
<p>If you have a noisy objective function, and the gaussian process model is tending to overfit to noisy data points (you can check logs/RetrospectiveModelFit.png to get an idea of this), you can increase the parameter <code class="docutils literal notranslate"><span class="pre">bayes_GP_alpha</span></code> which by default is set to .01. I haven’t figured out the exact meaning of this parameter, but basically you should make it larger if your model is being overfit!</p>
</section>
<section id="for-the-hard-core-nerds">
<h3>For the hard core nerds…<a class="headerlink" href="#for-the-hard-core-nerds" title="Link to this heading"></a></h3>
<p>The Bayesian optimisation is based on <a class="reference external" href="https://github.com/fmfn/BayesianOptimization">this code</a>. This code has a lot of options to tune that we don’t give you access to by default. But, if you really want to nerd out further, you can head to the Bayesian Optimisation site to learn more about this technique.</p>
</section>
</section>
<section id="neldermeadoptimiser">
<h2>NelderMeadOptimiser<a class="headerlink" href="#neldermeadoptimiser" title="Link to this heading"></a></h2>
<section id="choose-the-starting-simplex">
<h3>Choose the starting simplex<a class="headerlink" href="#choose-the-starting-simplex" title="Link to this heading"></a></h3>
<p>The NelderMead method is based on the concept of a simplex, which is a shape with [n+1] vertices, where n is the number of parameters. For instance, in a one dimension, the simplex has two vertices. The algorithm works by changing the position of these vertices according to a set of rules - expand, contract, reflect, or shrink.</p>
<p>Clearly, the position of the starting simplex will be of crucial importance in the convergence of this algorithm. Like a lot of things in optimisation, sometimes there can be more art than science in choosing the starting simplex well! In general, choosing it to span a larger space will result in more exploraratory behavior, while a smaller space will be quicker to converge but more likely to get stuck in a local minima (these are only rules of thumb!!). We provide three ways to choose the starting simplex, using the parameter <code class="docutils literal notranslate"><span class="pre">NM_StartingSimplex</span></code>:</p>
<ul class="simple">
<li><p>None: this will follow the default scipy, which will construct the starting simplex by expanding your starting position by 5%. So for example, in 1D, if your starting point is 1, your starting simplex would be [1, 1.05]</p></li>
<li><p>Float: this just replaces the 5% with another number, e.g. NM_StartingSimplex=.1, you will get [1, 1.1] in the example above.</p></li>
<li><p>List/array of size [n, n+1]: This allows you complete control over the starting simplex, e.g. for a two dimensional problem: NM_StartingSimplex = [[0.9, 0.9], [0.72, 0.9], [0.9, 0.72]]</p></li>
</ul>
</section>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="DevelopmentExample.html" class="btn btn-neutral float-left" title="Development example" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="EnvironmentSetup.html" class="btn btn-neutral float-right" title="Environment set up" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2021, Brendan Whelan(s).</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>